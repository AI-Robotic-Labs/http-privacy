#include "privacy_http_sdk/src/lib.rs.h" // Auto-generated by the `cxx` crate
#include <iostream>
#include <unordered_map>
#include <thread>
#include <nlohmann/json.hpp>
#include <pybind11/pybind11.h>
#include <pybind11/embed.h>
#include <httplib.h>
#include <fstream>

using json = nlohmann::json;
namespace py = pybind11;

// Python code to run Stable Diffusion (embedded via pybind11)
std::string run_stable_diffusion(const std::string& prompt, int width, int height, int steps) {
    py::scoped_interpreter guard{}; // Start Python interpreter
    try {
        auto module = py::module_::import("sys");
        module.attr("path").attr("append")("."); // Add current directory to Python path

        std::string code = R"(
import torch
from diffusers import StableDiffusionPipeline
import base64
from io import BytesIO
from PIL import Image

def generate_image(prompt, width, height, steps):
    pipe = StableDiffusionPipeline.from_pretrained(
        "runwayml/stable-diffusion-v1-5",
        torch_dtype=torch.float16,
        use_auth_token=False
    ).to("cuda" if torch.cuda.is_available() else "cpu")
    
    image = pipe(
        prompt,
        width=width,
        height=height,
        num_inference_steps=steps
    ).images[0]
    
    buffered = BytesIO()
    image.save(buffered, format="PNG")
    return base64.b64encode(buffered.getvalue()).decode("utf-8")
)";
        auto locals = py::dict();
        py::exec(code, py::globals(), locals);
        auto generate_image = locals["generate_image"];
        return generate_image(prompt, width, height, steps).cast<std::string>();
    } catch (const py::error_already_set& e) {
        throw std::runtime_error("Python error: " + std::string(e.what()));
    }
}

// Start the local Stable Diffusion API server
void start_api_server() {
    httplib::Server svr;

    svr.Post("/txt2img", [](const httplib::Request& req, httplib::Response& res) {
        try {
            json payload = json::parse(req.body);
            std::string prompt = payload["prompt"].get<std::string>();
            int width = payload["width"].get<int>();
            int height = payload["height"].get<int>();
            int steps = payload["steps"].get<int>();

            // Sanitize prompt (basic example)
            // Sanitize prompt (basic example)
            if (prompt.find("<script") != std::string::npos || prompt.find("..") != std::string::npos) {
                res.set_content("Invalid prompt", "text/plain");
                res.status = 400;
                return;
            }

            // Generate image
            std::string image_base64 = run_stable_diffusion(prompt, width, height, steps);

            json response = {
                {"image", image_base64}
            };
            res.set_content(response.dump(), "application/json");
        } catch (const std::exception& e) {
            res.set_content("Error: " + std::string(e.what()), "text/plain");
            res.status = 500;
        }
    });

    std::cout << "Starting Stable Diffusion API server on http://127.0.0.1:8080" << std::endl;
    svr.listen("127.0.0.1", 8080);
}

// Extend the privacy_http_sdk client interface
namespace privacy_http_sdk {
    // Assume HttpClient is the type returned by new_http_client()
    // If the actual type differs, adjust accordingly
    void generate_image(
        HttpClient& client,
        const std::string& prompt,
        int width,
        int height,
        int steps,
        const std::string& output_path
    ) {
        std::string url = "http://127.0.0.1:8080/txt2img";
        std::unordered_map<std::string, std::string> headers = {
            {"Content-Type", "application/json"}
        };

        json payload = {
            {"prompt", prompt},
            {"width", width},
            {"height", height},
            {"steps", steps}
        };

        std::string body = payload.dump();
        std::string response = client.post(url, headers, body);

        json response_json = json::parse(response);
        std::string image_data = response_json["image"].get<std::string>();

        // Decode base64 (placeholder; use a library like cpp-base64 for production)
        // For simplicity, assume image_data is already usable
        // Replace with actual base64 decoding in production
        std::string decoded = image_data; // TODO: Implement base64 decoding

        std::ofstream file(output_path, std::ios::binary);
        if (!file) {
            throw std::runtime_error("Failed to open output file: " + output_path);
        }
        file.write(decoded.c_str(), decoded.size());
        file.close();
    }
}

int main() {
    // Start the Stable Diffusion API server in a separate thread
    std::thread server_thread(start_api_server);

    // Wait briefly to ensure server starts
    std::this_thread::sleep_for(std::chrono::seconds(2));

    // Initialize the privacy_http_sdk client
    auto client = privacy_http_sdk::new_http_client();

    std::cout << "PrivacyHttpSdk Version: " << PRIVACY_HTTP_SDK_VERSION << std::endl;

    // Existing GET/POST requests (corrected typos and consolidated)
    std::unordered_map<std::string, std::string> headers = {
        {"Authorization", "Bearer YOUR_API_KEY"},
        {"Content-Type", "application/json"}
    };

    // Perform GET requests
    std::vector<std::string> urls = {
        "https://api.openai.com/v1/models",
        "https://api.gemini.google.com/v1/models", // Corrected URL
        "https://api.deepseek.com",
        "https://bedrock-runtime.us-east-1.amazonaws.com", // Specified region
        "https://api.x.ai/v1/models",
        "https://dashscope-intl.aliyuncs.com/compatible-mode/v1/chat/completions",
        "https://api.anthropic.com/v1/messages", // Corrected Claude URL
        "http://localhost:11434/api/generate" // Ollama local API
    };

    for (const auto& url : urls) {
        try {
            auto response = client->get(url, headers);
            std::cout << "GET Response from " << url << ": " << response << std::endl;
        } catch (const std::exception& e) {
            std::cerr << "GET Error from " << url << ": " << e.what() << std::endl;
        }
    }

    // Perform a POST request (example)
    try {
        std::string body = R"({"prompt": "Hello, world!", "max_tokens": 5})";
        auto response = client->post("https://api.openai.com/v1/completions", headers, body);
        std::cout << "POST Response: " << response << std::endl;
    } catch (const std::exception& e) {
        std::cerr << "POST Error: " << e.what() << std::endl;
    }

    // Perform Stable Diffusion image generation
    try {
        privacy_http_sdk::generate_image(*client, "A serene landscape", 512, 512, 50, "output.png");
        std::cout << "Image saved to output.png" << std::endl;
    } catch (const std::exception& e) {
        std::cerr << "Stable Diffusion Error: " << e.what() << std::endl;
    }

    // Keep the program running
    server_thread.join();
    return 0;
}